{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXIF Date-based File Copier\n",
    "\n",
    "This script scans (recursively) a directory of images, tries to get the best possible origin date for each image, and copies the images to new directory.\n",
    "\n",
    "I'm specifically **copying** instead of moving the files because the source of the images is a consolidated backup that should not be modified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequsites:\n",
    "- `pip install piexif exifread pillow progressbar2`\n",
    "- `brew install exiftool`\n",
    "\n",
    "For some older Canon photos, the `ExifRead` library chokes with one of:\n",
    "\n",
    "    Possibly corrupted field Tag 0x0001 in MakerNote IFD\n",
    "    Possibly corrupted field InteroperabilityIndex in Interoperability IFD\n",
    "    OSError: [Errno 22] Invalid argument\n",
    "    \n",
    "For some random other photos, the `piexif` library chokes:\n",
    "\n",
    "    error: unpack requires a buffer of 4 bytes\n",
    "\n",
    "In order, I try reading files with `piexif` then `ExifRead` then `PIL`, and if they all failed, I try execing out to `exiftool` because it does a _great_ job at the cost of forking another process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import pprint\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "import exifread\n",
    "import piexif\n",
    "import progressbar\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "from infinitewarp_utils import timing\n",
    "\n",
    "\n",
    "progressbar.streams.wrap_stderr()\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    source_dir = '/Volumes/Thorium/Backups/Dojo/Photos_Library'\n",
    "    archive_dir = os.path.expanduser('~/Pictures/full-archive')\n",
    "    output_dir = os.path.join(archive_dir, 'corrected-names')\n",
    "    fail_exif_dir = os.path.join(archive_dir, 'failed-exif')\n",
    "    fail_dupe_dir = os.path.join(archive_dir, 'failed-dupe')\n",
    "    log_path = os.path.join(archive_dir, 'process-log.txt')\n",
    "\n",
    "    @classmethod\n",
    "    def makedirs(cls):\n",
    "        os.makedirs(cls.output_dir, exist_ok=True)\n",
    "        os.makedirs(cls.fail_exif_dir, exist_ok=True)\n",
    "        os.makedirs(cls.fail_dupe_dir, exist_ok=True)\n",
    "\n",
    "Config.makedirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patterns(object):\n",
    "    desired_name = re.compile(r'^\\d{4}-\\d{2}-\\d{2} \\d{2}\\.\\d{2}\\.\\d{2}\\.[a-zA-Z]{3}[a-zA-Z]?$')\n",
    "    almost_desired_name_sub = re.compile(r'^(\\d{4}-\\d{2}-\\d{2} \\d{2}\\.\\d{2}\\.\\d{2})(.*)\\.([a-zA-Z]{3}[a-zA-Z]?)$')\n",
    "    almost_desired_name_rep = r'\\1.\\3'\n",
    "    \n",
    "    exif_date_sub = re.compile(r'(\\d{4}):(\\d{2}):(\\d{2} \\d{2})\\:(\\d{2})\\:(\\d{2})')\n",
    "    exif_date_rep = r'\\1-\\2-\\3.\\4.\\5.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseWrapper(object):\n",
    "    @classmethod\n",
    "    def get_created_date(cls, filepath):\n",
    "        tags = cls.get_tags(filepath)\n",
    "        return cls.pick_date_tag(tags)\n",
    "\n",
    "    @classmethod\n",
    "    def dump(cls, filepath):\n",
    "        tags = cls.get_tags(filepath)\n",
    "        print(tags)\n",
    "    \n",
    "\n",
    "class ExifreadWrapper(BaseWrapper):\n",
    "    \"\"\"ExifRead wrapper.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_tags(filepath):\n",
    "        with open(filepath, 'rb') as fp:\n",
    "            return exifread.process_file(fp)\n",
    "        \n",
    "    @staticmethod\n",
    "    def pick_date_tag(tags):\n",
    "        return (tags.get('Image DateTime') or tags.get('EXIF DateTimeOriginal')).values\n",
    "\n",
    "\n",
    "class PiexifWrapper(BaseWrapper):\n",
    "    \"\"\"piexif wrapper.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_tags(filepath):\n",
    "        return piexif.load(filepath)\n",
    "        \n",
    "    @staticmethod\n",
    "    def pick_date_tag(tags):\n",
    "        exif = tags.get('Exif')\n",
    "        return (\n",
    "            exif.get(piexif.ExifIFD.DateTimeDigitized) or exif.get(piexif.ExifIFD.DateTimeOriginal)\n",
    "        ).decode('utf-8')\n",
    "    \n",
    "    @classmethod\n",
    "    def dump(cls, filename):\n",
    "        tags = cls.get_tags(filename)\n",
    "        tags.pop(\"thumbnail\")\n",
    "        for ifd_name in exif_dict:\n",
    "            print(\"\\n{0} IFD:\".format(ifd_name))\n",
    "            for key in tags[ifd_name]:\n",
    "                try:\n",
    "                    print(key, tags[ifd_name][key][:20])\n",
    "                except:\n",
    "                    print(key, tags[ifd_name][key])\n",
    "\n",
    "\n",
    "class PillowWrapper(BaseWrapper):\n",
    "    \"\"\"PIL wrapper.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_tags(filepath):\n",
    "        tags = {}\n",
    "        info = Image.open(filepath)._getexif()\n",
    "        for tag, value in info.items():\n",
    "            decoded = TAGS.get(tag, tag)\n",
    "            tags[decoded] = value\n",
    "        return tags\n",
    "        \n",
    "    @staticmethod\n",
    "    def pick_date_tag(tags):\n",
    "        return (tags.get('Image DateTime') or tags.get('EXIF DateTimeOriginal')).values\n",
    "\n",
    "    @classmethod\n",
    "    def get_created_date(cls, filepath):\n",
    "        tags = cls.get_tags(filepath)\n",
    "        return tags.get('DateTime') or tags.get('DateTimeDigitized') or tags.get('DateTimeOriginal')\n",
    "\n",
    "\n",
    "class ExiftoolWrapper(BaseWrapper):\n",
    "    \"\"\"exiftool CLI wrapper.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_tags(filepath):\n",
    "        completed = subprocess.run(['exiftool', filepath], stdout=subprocess.PIPE)\n",
    "        exif_dict = {}\n",
    "        for line in completed.stdout.split(b'\\n'):\n",
    "            try:\n",
    "                line = line.decode('utf-8')\n",
    "            except:\n",
    "                continue\n",
    "            if ':' in line:\n",
    "                loc = line.find(':')\n",
    "                key = line.split(':')[0]\n",
    "                value = line[len(key) + 1:]\n",
    "                exif_dict[key.strip()] = value.strip()\n",
    "        return exif_dict\n",
    "        \n",
    "    @staticmethod\n",
    "    def pick_date_tag(tags):\n",
    "        return tags.get('Date/Time Original') or tags.get('Create Date') or tags.get('Modify Date')\n",
    "\n",
    "\n",
    "def get_exif_date(filepath):\n",
    "    \"\"\"Get the effective \"created\" date in the EXIF metadata.\"\"\"\n",
    "    wrappers = [\n",
    "        ExifreadWrapper,\n",
    "        PiexifWrapper,\n",
    "        PillowWrapper,\n",
    "        ExiftoolWrapper,\n",
    "    ]\n",
    "\n",
    "    for wrapper in wrappers:\n",
    "        try:\n",
    "            value = wrapper.get_created_date(filepath)\n",
    "            if value is not None:\n",
    "                return value\n",
    "        except Exception as e:\n",
    "            logger.error(e)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example files with problematic exif data for some of the libraries\n",
    "files = [\n",
    "#     '/Volumes/Thorium/Backups/Dojo/Photos_Library/Chronological/2003-04/IMG_0054.jpg',  # Possibly corrupted field Tag 0x0001 in MakerNote IFD\n",
    "#     '/Volumes/Thorium/Backups/Dojo/Photos_Library/Chronological/2003-11/IMG_1761B.jpg',  # mangled bytes in 'Canon Image Type' and 'Canon Firmware Version'\n",
    "#     '/Volumes/Thorium/Backups/Dojo/Photos_Library/Chronological/2003-11/IMG_1788B.jpg',  # Possibly corrupted field InteroperabilityIndex in Interoperability IFD\n",
    "#     '/Volumes/Thorium/Backups/Dojo/Photos_Library/Chronological/2005-12/IMG_3796.jpg',  # ???\n",
    "#     os.path.expanduser('~/Pictures/old photos/IMG_1667.JPG'),  # Possibly corrupted field Tag 0x0001 in MakerNote IFD\n",
    "#     '/Volumes/Thorium/Backups/Dojo/Photos_Library/More Archives/iPhone Downloads - 2013-05-13 Prime/IMG_0080.JPG',  # empty\n",
    "]\n",
    "file_dates = [(f, get_exif_date(f)) for f in files]\n",
    "pprint.pprint(file_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ideal_name(filepath):\n",
    "    \"\"\"Determine desired filename for given JPEG filename.\"\"\"\n",
    "    filename = os.path.basename(filepath)\n",
    "    if Patterns.desired_name.match(filename):\n",
    "        return filename\n",
    "    new_filename = Patterns.almost_desired_name_sub.sub(Patterns.almost_desired_name_rep, filename).lower()\n",
    "    if Patterns.desired_name.match(new_filename):\n",
    "        return new_filename\n",
    "    created_date = get_exif_date(filepath)\n",
    "    if created_date is None:\n",
    "        return None\n",
    "    new_filename = Patterns.exif_date_sub.sub(Patterns.exif_date_rep, created_date).lower()\n",
    "    if Patterns.desired_name.match(new_filename):\n",
    "        return new_filename\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_all_files(source_dir):\n",
    "    return glob.glob(os.path.join(source_dir,'**', '*.*'), recursive=True)\n",
    "\n",
    "\n",
    "def get_processable_paths(file_paths):\n",
    "    \"\"\"Split found paths into lists of files we can handle, files we should note, and files we don't care about.\"\"\"\n",
    "\n",
    "    file_extensions = (\n",
    "        'bmp',\n",
    "        'jpg',\n",
    "        'png',\n",
    "        'tif',\n",
    "        'tiff',\n",
    "    )\n",
    "    noted_extensions = (\n",
    "        'avi',\n",
    "        'psd',\n",
    "        'mov',\n",
    "        'mp4',\n",
    "        'mpg',\n",
    "        'm4v',\n",
    "        'aif',\n",
    "        'aiff',\n",
    "        'wav',\n",
    "        'xcf',\n",
    "    )\n",
    "    image_paths = []\n",
    "    noted_paths = []\n",
    "    trash_paths = []\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        ext = file_path.split('.')[-1].lower()\n",
    "        if ext in file_extensions:\n",
    "            image_paths.append(file_path)\n",
    "        elif ext in noted_extensions:\n",
    "            noted_paths.append(file_path)\n",
    "        else:\n",
    "            trash_paths.append(file_path)\n",
    "    \n",
    "    return image_paths, noted_paths, trash_paths\n",
    "\n",
    "\n",
    "def prepare_copy_renames(source_dir=None, use_multiprocessing=False):\n",
    "    \"\"\"Prepare list of file copy/rename operations.\"\"\"\n",
    "    if not source_dir:\n",
    "        source_dir = Config.source_dir\n",
    "    \n",
    "    new_names = []\n",
    "    exif_failures = []\n",
    "    dupe_failures = []\n",
    "    copies = []\n",
    "\n",
    "    image_paths, noted_paths, trash_paths = get_processable_paths(find_all_files(source_dir))\n",
    "    \n",
    "    bar = progressbar.ProgressBar()\n",
    "    if use_multiprocessing:\n",
    "        with multiprocessing.Pool(processes=4) as pool:\n",
    "            multiple_results = [(pool.apply_async(get_ideal_name, (filepath,)), filepath) for filepath in image_paths]\n",
    "            new_filenames_for_paths = [(res.get(), filepath) for res, filepath in bar(multiple_results)]\n",
    "    else:\n",
    "        new_filenames_for_paths = [(get_ideal_name(filepath), filepath) for filepath in bar(image_paths)]\n",
    "    \n",
    "    for new_filename, filepath in new_filenames_for_paths:\n",
    "        if new_filename is None:\n",
    "            logger.info('cannot determine name for \"{}\" because EXIF processing failed'.format(filepath))\n",
    "            exif_failures.append(filepath)\n",
    "            continue\n",
    "        if new_filename in new_names:\n",
    "            logger.info('cannot copy \"{}\" to \"{}\" because it already exists'.format(filepath, new_filename))\n",
    "            dupe_failures.append((filepath, new_filename))\n",
    "            continue\n",
    "        new_names.append(new_filename)\n",
    "        copies.append((filepath, new_filename))\n",
    "\n",
    "    return copies, exif_failures, dupe_failures, noted_paths, trash_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datestamped_filename(filepath, filename=None):\n",
    "    if not filename:\n",
    "        filename = os.path.basename(filepath)\n",
    "    filename_extension = filename.split('.')[-1]\n",
    "    filename_base = filename[:-(len(filename_extension)+1)]\n",
    "    new_filename = '{}-{}.{}'.format(filename_base, time.time(), filename_extension)\n",
    "    return new_filename\n",
    "    \n",
    "\n",
    "def do_copies(copies, exif_failures, dupe_failures, logpath):\n",
    "    with open(logpath, 'a') as log_fp:\n",
    "        print('-' * 70, file=log_fp)\n",
    "        print('exif failures', file=log_fp)\n",
    "        print('-' * 70, file=log_fp)\n",
    "        for filepath in exif_failures:\n",
    "            new_filepath = os.path.join(Config.fail_exif_dir, datestamped_filename(filepath))\n",
    "            line = f'{filepath} → {new_filepath}'\n",
    "            print(line, file=log_fp)\n",
    "            shutil.copy(filepath, new_filepath)\n",
    "        print('-' * 70, file=log_fp)\n",
    "        print('dupe failures', file=log_fp)\n",
    "        print('-' * 70, file=log_fp)\n",
    "        for filepath, new_filename in dupe_failures:\n",
    "            new_filepath = os.path.join(Config.fail_dupe_dir, datestamped_filename(filepath, new_filename))\n",
    "            line = f'{filepath} → {new_filepath}'\n",
    "            print(line, file=log_fp)\n",
    "            shutil.copy(filepath, new_filepath)\n",
    "        print('-' * 70, file=log_fp)\n",
    "        print('copies', file=log_fp)\n",
    "        print('-' * 70, file=log_fp)\n",
    "        for filepath, new_filename in copies:\n",
    "            new_filepath = os.path.join(Config.output_dir, new_filename)\n",
    "            line = f'{filepath} → {new_filepath}'\n",
    "            print(line, file=log_fp)\n",
    "            shutil.copy(filepath, new_filepath)\n",
    "        print('-' * 70, file=log_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where the magic happens, folks!\n",
    "\n",
    "with timing.Timer(action=f'execute prepare_copy_renames({Config.source_dir})', verbose=True):\n",
    "    copies, exif_failures, dupe_failures, noted_paths, trash_paths = prepare_copy_renames(Config.source_dir)\n",
    "\n",
    "len(copies), len(exif_failures), len(dupe_failures), len(noted_paths), len(trash_paths)\n",
    "\n",
    "with timing.Timer(action='do_copies', verbose=True):\n",
    "    do_copies(copies, exif_failures, dupe_failures, Config.log_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
